{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "216psfGPwbHS"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "\n",
        "import googlesearch as g # use to search keywords in google\n",
        "from googlesearch import search\n",
        "import time\n",
        "import random\n",
        "import requests\n",
        "from urllib.parse import urlparse # use to parse out the domain of the url links\n",
        "from datetime import datetime # use to get date and time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e40vg5nrRGfU"
      },
      "outputs": [],
      "source": [
        "# putting the keywords in a list of strings\n",
        "# each keyword with capitalization format so that it can later be used as search term as well as title of txt file\n",
        "\n",
        "keywords = [\"Corporate Health\", \"Top News\", \"Menstrual Health\", \"Athletes\", \"Research\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNcgkSABX3mU"
      },
      "outputs": [],
      "source": [
        "# function to check if the txt file is empty or already populated with list of article links\n",
        "# input: string title to locate the correct txt file\n",
        "# output: boolean True if the txt file already has list, False if txt file is empty\n",
        "\n",
        "def checkFile(title):\n",
        "  with open(title + ' Article Links.txt', 'r') as f: # must already have txt file in location with name keyword + article links\n",
        "    first_char = f.read(1) # get the first character of the file\n",
        "    f.close()\n",
        "    if first_char:\n",
        "      return True # if a character is present, then the file is not empty\n",
        "    else:\n",
        "      return False # if a character is not present, then the file is empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfly0nBdINSg"
      },
      "outputs": [],
      "source": [
        "# function to take in the current list of articles and create a list of unique domains from the urls\n",
        "# input: list urls which is the list of urls to be parsed\n",
        "# output: set unique_domains which is a set of the unique domains, no repeats\n",
        "\n",
        "def generateDomains(urls):\n",
        "  unique_domains = set()\n",
        "  for i in urls: # already know the links are unique, checked for uniqueness when added originally\n",
        "    domain = urlparse(i).netloc # find just the domain of the link\n",
        "    unique_domains.add(domain) # already know that the domains are unique, checked for uniqueness when added originally\n",
        "  return unique_domains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tXyikH0KzqM"
      },
      "outputs": [],
      "source": [
        "# function to add new links from new list of articles to the old list of articles, ensuring unique domains\n",
        "# input: list url_original which is the new list of articles\n",
        "  # list url_current which is the old list of articles\n",
        "  # set unique_domains which is the set of unique domains from the old list of articles\n",
        "# output: list url_final which is the final list of articles\n",
        "  # after only new articles with unique domains have been added to the old list\n",
        "\n",
        "def addDomainsAndUpdateList(url_original, url_current, unique_domains):\n",
        "  url_final = url_current # add the current list of articles to the final list\n",
        "  for i in url_original: # iterating over the newly found links\n",
        "    if i not in url_final: # check that the newly found links are not already in the current list before adding\n",
        "      domain = urlparse(i).netloc # find just the domain of the link\n",
        "      if domain not in unique_domains: # check that the newly found links are not the same domain as another in the current list\n",
        "        unique_domains.add(domain) # update the current list of unique domains so the new links do not overlap on each other\n",
        "        url_final.append(i) # can finally add the link if not already added and if the domain is unique\n",
        "  return url_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gjf3tUoKWLA"
      },
      "outputs": [],
      "source": [
        "# function to take in the current list of articles, add new links if not already listed\n",
        "# input: string keyword, list url_old which is the current list of articles in the txt file\n",
        "# output: list url_all which is the updated list of old and new articles, no repeats\n",
        "\n",
        "def addLinks_test(keyword, url_old):\n",
        "  url_new = list(g.search(\"women's health \" + keyword, stop = 10, lang = 'en')) # search for articles, put links in a list\n",
        "  domains_current = generateDomains(url_old) # make a list of the unique domains that are in the current list of links\n",
        "  url_all = addDomainsAndUpdateList(url_new, url_old, domains_current) # check that links are not already in the list and have unique domains\n",
        "  random.shuffle(url_all) # shuffle the list of articles so not in any order, get more variety\n",
        "  return url_all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def addLinks(keyword, url_old):\n",
        "    query = \"women's health \" + keyword\n",
        "    url_new = []\n",
        "\n",
        "    # Perform the search and limit the results manually\n",
        "    for url in search(query, num_results=10, lang='en'):\n",
        "        url_new.append(url)\n",
        "\n",
        "    domains_current = generateDomains(url_old)  # Generate a list of unique domains\n",
        "    url_all = addDomainsAndUpdateList(url_new, url_old, domains_current)  # Update the list with unique domains\n",
        "    random.shuffle(url_all)  # Shuffle the list for variety\n",
        "    return url_all"
      ],
      "metadata": {
        "id": "VX0Srkuk-CrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftQe-qE_6Xh1"
      },
      "outputs": [],
      "source": [
        "# function to get the current date and time\n",
        "# input: none\n",
        "# output: list dt_list giving information as [date, time]\n",
        "\n",
        "def getDataAndTime():\n",
        "  now = datetime.now() # get now using datetime\n",
        "  dt = now.strftime(\"%d/%m/%Y %H:%M:%S\") # date and time given as dd/mm/YY H:M:S\n",
        "  dt_string = str(dt) # reformat as a string\n",
        "  dt_list = list(dt_string.split()) # separating out date and time\n",
        "  return dt_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eou9u9RD2F8n"
      },
      "outputs": [],
      "source": [
        "# function to get the length of the list of articles\n",
        "# input: list urls\n",
        "# output: string total which is the numeric length of the list\n",
        "\n",
        "def getLength(urls):\n",
        "  total = str(len(urls))\n",
        "  return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrn_uhGhvy7s"
      },
      "outputs": [],
      "source": [
        "# function to convert the list of urls to a string format so it can be added to the txt file\n",
        "# input: list url_list\n",
        "# output: string url_string of the original list in string format\n",
        "\n",
        "def listToString(url_list):\n",
        "  url_string = \"\"\n",
        "  for i in url_list:\n",
        "      url_string += i + \", \" # separating links with \", \" so it still looks like a list\n",
        "  url_string = url_string[:-2] # getting rid of the final \", \"\n",
        "  return url_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C1HpE2i2O9C"
      },
      "outputs": [],
      "source": [
        "# function to clear out current txt file and put in the new date, time, length of the list, and updated links\n",
        "# input: string title to locate the txt file\n",
        "  # string date which is the current date\n",
        "  # string time which is the current time\n",
        "  # string length which gives the number of articles in the list\n",
        "  # string content which is the updated links to populate the txt file\n",
        "# output: none, txt files should be populated with new content\n",
        "\n",
        "def writeFile(title, date, time, length, content):\n",
        "  with open(title + ' Article Links.txt', 'w') as f:\n",
        "    f.truncate(0) # clear out current contents of the file\n",
        "    f.write(date) # add in the date\n",
        "    f.write(time) # add in the time\n",
        "    f.write(length) # add in the length of the list of articles\n",
        "    f.write(content) # add in the updated list of links as a string\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to download the txt files\n",
        "# input: string title to locate the txt file\n",
        "# output: none, txt files should be downloaded\n",
        "\n",
        "def downloadFile(title):\n",
        "  files.download(title + ' Article Links.txt')"
      ],
      "metadata": {
        "id": "qjZvloZlYnLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_GAbFq686Ai"
      },
      "outputs": [],
      "source": [
        "# function to read txt files, store the contents, and convert from a string to list format so the list can be updated\n",
        "# input: string title to locate the correct txt file\n",
        "# output: list url_current which is list of urls contained in the txt file\n",
        "\n",
        "def readFile(title):\n",
        "  with open(title + ' Article Links.txt', 'r') as f:\n",
        "    next(f) # skip first line which is the date\n",
        "    next(f) # skip second line which is the time\n",
        "    next(f) # skip third line which is the length of the list\n",
        "    url_read = f.read() # begin reading 2 lines down, url_read is a string\n",
        "    f.close()\n",
        "  url_current = list(url_read.split(\", \")) # convert content from a string to a list\n",
        "  return url_current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWO0Yr0lT50U"
      },
      "outputs": [],
      "source": [
        "# function to edit the txt files and add new article links\n",
        "# input: string topic to be used in keyword google search\n",
        "# output: none, txt fils should be updated\n",
        "\n",
        "def replaceFile(topic):\n",
        "  if not checkFile(topic): # check if the file is entirely empty\n",
        "    url_old = [] # if the file is empty, then the current list of articles is empty\n",
        "  else: # if the file is not empty, it will have a current list of articles to be read and updated\n",
        "    url_old = readFile(topic) # read the current list of articles\n",
        "  url_list = addLinks(topic, url_old) # add links to the the curerent list of articles in list form\n",
        "  date = \"Date: \" + str(getDataAndTime()[0]) + \"\\n\" # reformatting date by itself\n",
        "  time = \"Time: \" + str(getDataAndTime()[1]) + \"\\n\" # reformatting time by itself\n",
        "  length = length = \"Length: \" + getLength(url_list) + \" Articles\" + \"\\n\" # reformatting the length by itself\n",
        "  url_string = listToString(url_list) # change the list to string form compatible with txt file\n",
        "  writeFile(topic, date, time, length, url_string) # add new contents to the files\n",
        "  #downloadFile(topic) # implement if want to download the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlelJFhjVRsI"
      },
      "outputs": [],
      "source": [
        "# populating the txt files links\n",
        "\n",
        "for i in keywords: # populate a txt file for each of the keywords\n",
        "  replaceFile(i) # replace the file with a file that has an updated list of articles"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}