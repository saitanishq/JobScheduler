{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "216psfGPwbHS"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "\n",
        "import googlesearch as g\n",
        "import time\n",
        "import random\n",
        "import requests\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting to google drive in order to pull txt files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYIlwRBqV4vF",
        "outputId": "1decf7ee-1daf-47fe-e9e5-f155eeaafe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B43tQfH9yWdG"
      },
      "outputs": [],
      "source": [
        "# getting the date and time as strings\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now() # get now using datetime\n",
        "dt = now.strftime(\"%d/%m/%Y %H:%M:%S\") # date and time given as dd/mm/YY H:M:S\n",
        "dt_string = str(dt) # reformat as a string\n",
        "\n",
        "dt_list = list(dt_string.split()) # separating out date and time\n",
        "date = \"Date: \" + str(dt_list[0]) + \"\\n\" # reformating date by itself\n",
        "time = \"Time: \" + str(dt_list[1]) + \"\\n\" # reformating time by itself"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# putting the keywords in a list of strings\n",
        "# each keyword with capitalization format so that it can later be used as search term as well as title of txt file\n",
        "\n",
        "keywords = [\"Corporate Health\", \"Top News\", \"Menstrual Health\", \"Athletes\", \"Research\"]"
      ],
      "metadata": {
        "id": "e40vg5nrRGfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populating the original empty txt files with first round of links\n",
        "\n",
        "for i in keywords:\n",
        "  populateOriginalFile(i)"
      ],
      "metadata": {
        "id": "rlelJFhjVRsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding new links to the current list of links from the txt files\n",
        "\n",
        "for i in keywords:\n",
        "  readAndReplace(i)"
      ],
      "metadata": {
        "id": "oAjmkC95VS2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create original list of liks and add to the empty txt files\n",
        "# input: string topic to be used in keyword google search\n",
        "# output: none\n",
        "\n",
        "def populateOriginalFile(topic):\n",
        "  url_list = generateLinks(topic)\n",
        "  url_string = listToString(url_list)\n",
        "  writeFile(topic, url_string)"
      ],
      "metadata": {
        "id": "jWO0Yr0lT50U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to take the links from the current txt file, add new links, and update the txt file\n",
        "# input: string topic to be used in keyword google search\n",
        "# output: none\n",
        "\n",
        "def readAndReplace(topic):\n",
        "    url_old = readFile(topic)\n",
        "    url_string = listToString(addLinks(topic, url_old))\n",
        "    writeFile(topic, url_string)"
      ],
      "metadata": {
        "id": "YiNURWJlOZur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate initial list of articles\n",
        "# input: string keyword used for google search\n",
        "# output: list urls of url links\n",
        "\n",
        "def generateLinks(keyword):\n",
        "  urls = list(g.search(\"women's health \" + keyword,stop=1000, lang='en')) # search for articles, put links in a list\n",
        "\n",
        "  # make sure that the links added have unique domains to not repeat the same sources\n",
        "  urls_final = []\n",
        "  unique_domains = set()\n",
        "  for i in urls:\n",
        "    domain = urlparse(i).netloc\n",
        "    if domain not in unique_domains:\n",
        "      unique_domains.add(domain)\n",
        "      urls_final.append(i)\n",
        "\n",
        "  random.shuffle(urls_final) # shuffle the list of articles so not in any order, get more variety\n",
        "  return urls_final"
      ],
      "metadata": {
        "id": "esX-v196VXVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrn_uhGhvy7s"
      },
      "outputs": [],
      "source": [
        "# function to convert the list of urls to a string format so it can be added to the txt file\n",
        "# input: list url_lists\n",
        "# output: string url_string\n",
        "\n",
        "def listToString(url_list):\n",
        "    url_string = \"\"\n",
        "    for i in url_list:\n",
        "        url_string += i + \", \" # separating links with \", \" so it still looks like a list\n",
        "    url_string = url_string[:-2] # getting rid of the final \", \"\n",
        "    return url_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_GAbFq686Ai"
      },
      "outputs": [],
      "source": [
        "# function to read txt files, store the contents, and convert from a string to list format so the list can be updated\n",
        "# input: string title to locate the correct txt file\n",
        "# output: list url_current which is list of urls contained in the txt file\n",
        "\n",
        "def readFile(title):\n",
        "  with open('/content/drive/My Drive/' + title + ' Article Links.txt', 'r') as f:\n",
        "    next(f) # skip first line which is the date\n",
        "    next(f) # skip second line which is the time\n",
        "    url_read = f.read() # begin reading 2 lines down, url_read is a string\n",
        "    f.close()\n",
        "  url_current = list(url_read.split(\", \")) # convert content from a string to a list\n",
        "  return url_current"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to take in the current list of articles, add new links if not already listed\n",
        "# input: string keyword, list url_old which is the current list of articles in the txt file\n",
        "# output: list url_all which is the updated list of old and new articles, no repeats\n",
        "\n",
        "def addLinks(keyword, url_old):\n",
        "  url_all = url_old # add the current list of articles to the final list\n",
        "  url_new = list(g.search(\"women's health \" + keyword,stop=1000, lang='en')) # search for articles, put links in a list\n",
        "\n",
        "  # make a list of the domains that are in the current list of links\n",
        "  unique_domains = set()\n",
        "  for i in url_all:\n",
        "    domain = urlparse(i).netloc\n",
        "    if domain not in unique_domains:\n",
        "        unique_domains.add(domain)\n",
        "\n",
        "  # for the new articles found, check that they are not already in the list and have unique domains\n",
        "  for i in url_new:\n",
        "    if i not in url_all: # check that the newly found link is not already in url_all before adding\n",
        "      domain = urlparse(i).netloc\n",
        "      if domain not in unique_domains:\n",
        "        unique_domains.add(domain)\n",
        "        url_all.append(i)\n",
        "\n",
        "  random.shuffle(url_all) # shuffle the list of articles so not in any order, get more variety\n",
        "  return url_all"
      ],
      "metadata": {
        "id": "i1wzqxbrHx8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C1HpE2i2O9C"
      },
      "outputs": [],
      "source": [
        "# function to clear out current txt file and put in date/time and updated links\n",
        "# input: string title to locate the txt file, string content which is the updated links to populate the txt file\n",
        "# output: none\n",
        "\n",
        "def writeFile(title, content):\n",
        "  with open('/content/drive/My Drive/' + title + ' Article Links.txt', 'w') as f:\n",
        "    f.truncate(0) # clear out current contents of the file\n",
        "    f.write(date) # add in the date\n",
        "    f.write(time) # add in the time\n",
        "    f.write(content) # add in the updated list of links as a string\n",
        "    f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}